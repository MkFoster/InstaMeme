# üì∏ InstaMeme ‚Äî On-Device AI Meme Generator for iOS

InstaMeme is a fully on-device, privacy-first meme creation app powered by Apple Silicon and the MLX framework.  
With just a photo and a tap, InstaMeme generates short, punchy meme captions using **local inference**‚Äîno internet connection required.

Users can:
- Take a live photo or pick from their library  
- Auto-generate meme captions using Vision + Llama running in MLX  
- Remix memes endlessly  
- Share or export them as burned-in images  
- Build and extend a persistent personal meme gallery  

InstaMeme transforms casual camera moments into share-ready memes instantly‚Äîall processed locally on ARM hardware.

---

## üöÄ InstaMeme Highlights

InstaMeme demonstrates **on-device AI** with a fun user experience.

This project showcases:

| Category | Achievement |
|---------|------------|
| **Technological Implementation** | Uses Apple‚Äôs MLX, on-device LLM inference, Vision classification, SwiftData persistence, and zero-server architecture. |
| **User Experience** | Designed as a frictionless meme workflow: snap ‚Üí suggest ‚Üí remix ‚Üí share. |
| **Impact** | Demonstrates a pattern for developers to incorporate on-device LLMs and generative UX flows in consumer apps. |
| **WOW Factor** | Watching a live camera image turn instantly into a meme‚Äîwith no network. |

InstaMeme showcases how the next wave of mobile apps can use **fast, private, localized intelligence** powered by Arm.

---

## ‚ú® Core Features

- üß† **On-Device Caption Generation**  
  Uses MLX + a quantized Llama-based language model for offline meme text.

- üì∑ **Live Camera Capture OR Photo Library Import**  
  Built with modern SwiftUI + PhotosPicker integration.

- üëÄ **Apple Vision Recognition**  
  Vision framework detects objects in the image, feeding semantic context into the LLM.

- üñºÔ∏è **Burn-In Graphics Rendering**  
  Exported memes are rendered into a final flattened image, guaranteeing compatibility with SMS, Messenger, WhatsApp, etc.

- ‚ôªÔ∏è **Remix Mode**  
  Users can regenerate new captions or edit them manually, creating variations without losing prior versions.

- üíæ **SwiftData Storage**  
  Fully persistent offline gallery that never requires a connection.

- üîÑ **Resizable Image Pipeline**  
  Automatically scales images to mobile-friendly dimensions to prevent memory overuse when sharing.

---

## üõ†Ô∏è Tech Stack

| Component | Technology |
|----------|------------|
| UI | SwiftUI |
| Storage | SwiftData |
| ML Framework | **MLX** + MLXLLM |
| Computer Vision | Apple **Vision Framework** |
| Model Execution | Quantized on-device Llama variant |
| Rendering | UIKit + SwiftUI `ImageRenderer`, Core Graphics burn-in |
| Platform | iOS (Apple Silicon / A-Series ARM chips) |

---

## üì¶ Setup & Build Instructions

### Requirements

- macOS Tahoe or later  
- Xcode 26 or later  
- **Apple Silicon Mac**
- iPhone running iOS 17+ (**required for live camera + on-device ML performance**)  

### 1Ô∏è‚É£ Clone the Repository

```sh
git clone https://github.com/MkFoster/InstaMeme
cd InstaMeme
```

### 2Ô∏è‚É£ Open in Xcode
open InstaMeme.xcodeproj

### 3Ô∏è‚É£ Add Required MLX Packages

In Xcode:

File ‚Üí Add Packages‚Ä¶

Add these URLs:

* https://github.com/ml-explore/mlx-swift.git
* https://github.com/ml-explore/mlx-swift-lm.git
* https://github.com/ml-explore/mlx-swift-llm.git

Confirm they are attached to the app target in:

Project Settings ‚Üí Target ‚Üí Frameworks, Libraries, and Embedded Content

### 4Ô∏è‚É£ Build and Run on a Physical Device
Because the app uses:
* Camera input
* Vision framework
* MLX running on-device
* Neural Engine acceleration

‚Ä¶it must run on real hardware.

Select your device in Xcode and press ‚åò + R

### 5Ô∏è‚É£ First-Run Model Download

When you tap Suggest Captions for the first time:
* The app will automatically download the quantized MLX model.
* It is stored locally and reused ‚Äî no internet needed afterward.
